{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6038acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "032a8a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "homelessness = pd.read_csv('homelessness.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63528f92",
   "metadata": {},
   "source": [
    "# Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e54165",
   "metadata": {},
   "source": [
    "They summarize and tell you about your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eff76952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>4887681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>735139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Mountain</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>7158024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>West South Central</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3009733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>California</td>\n",
       "      <td>109008.0</td>\n",
       "      <td>20964.0</td>\n",
       "      <td>39461588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              region       state  individuals  family_members  \\\n",
       "0           0  East South Central     Alabama       2570.0           864.0   \n",
       "1           1             Pacific      Alaska       1434.0           582.0   \n",
       "2           2            Mountain     Arizona       7259.0          2606.0   \n",
       "3           3  West South Central    Arkansas       2280.0           432.0   \n",
       "4           4             Pacific  California     109008.0         20964.0   \n",
       "\n",
       "   state_pop  \n",
       "0    4887681  \n",
       "1     735139  \n",
       "2    7158024  \n",
       "3    3009733  \n",
       "4   39461588  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homelessness.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb66caf",
   "metadata": {},
   "source": [
    "## Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55590533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7225.78431372549"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homelessness[\"individuals\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eecd4d",
   "metadata": {},
   "source": [
    "Similarly there are median(), mode(), min(), max(), var(), std(), sum(), quantile(),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cde1ca",
   "metadata": {},
   "source": [
    "## Summarizing Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f98359",
   "metadata": {},
   "source": [
    "You can use .min() for date columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b75965c",
   "metadata": {},
   "source": [
    "## .agg() method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195dd7e8",
   "metadata": {},
   "source": [
    "Allows you to compute custom summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e209e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct30(column):\n",
    "    return column.quantile(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002990e7",
   "metadata": {},
   "source": [
    "The following gives the 30th percentile of the homeless individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c36d40aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1745.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homelessness['individuals'].agg(pct30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cebb4aa",
   "metadata": {},
   "source": [
    "agg can also be used in more than one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7f01692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "individuals       1745.0\n",
       "family_members     676.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homelessness[['individuals','family_members']].agg(pct30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5bd578",
   "metadata": {},
   "source": [
    "The following is the function for the 40th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b3195fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct40(column):\n",
    "    return column.quantile(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39d780cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pct30    1745.0\n",
       "pct40    2540.0\n",
       "Name: individuals, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homelessness['individuals'].agg([pct30,pct40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1571c58d",
   "metadata": {},
   "source": [
    "## Cumulative Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d69815b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2570.0\n",
       "1       4004.0\n",
       "2      11263.0\n",
       "3      13543.0\n",
       "4     122551.0\n",
       "5     130158.0\n",
       "6     132438.0\n",
       "7     133146.0\n",
       "8     136916.0\n",
       "9     158359.0\n",
       "10    165302.0\n",
       "11    169433.0\n",
       "12    170730.0\n",
       "13    177482.0\n",
       "14    181258.0\n",
       "15    182969.0\n",
       "16    184412.0\n",
       "17    187147.0\n",
       "18    189687.0\n",
       "19    191137.0\n",
       "20    196051.0\n",
       "21    202862.0\n",
       "22    208071.0\n",
       "23    212064.0\n",
       "24    213088.0\n",
       "25    216864.0\n",
       "26    217847.0\n",
       "27    219592.0\n",
       "28    226650.0\n",
       "29    227485.0\n",
       "30    233533.0\n",
       "31    235482.0\n",
       "32    275309.0\n",
       "33    281760.0\n",
       "34    282227.0\n",
       "35    289156.0\n",
       "36    291979.0\n",
       "37    303118.0\n",
       "38    311281.0\n",
       "39    312028.0\n",
       "40    315110.0\n",
       "41    315946.0\n",
       "42    322085.0\n",
       "43    341284.0\n",
       "44    343188.0\n",
       "45    343968.0\n",
       "46    347896.0\n",
       "47    364320.0\n",
       "48    365341.0\n",
       "49    368081.0\n",
       "50    368515.0\n",
       "Name: individuals, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homelessness['individuals'].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d6f4c",
   "metadata": {},
   "source": [
    "This returns a number for each row of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8335270",
   "metadata": {},
   "source": [
    "Pandas also has methods for other cumulative statistics such as cummax, cummin, cumprod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c92c0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('sales_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eb0851e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  store type  department        date  weekly_sales  is_holiday  \\\n",
      "0           0      1    A           1  2010-02-05      24924.50       False   \n",
      "1           1      1    A           1  2010-03-05      21827.90       False   \n",
      "2           2      1    A           1  2010-04-02      57258.43       False   \n",
      "3           3      1    A           1  2010-05-07      17413.94       False   \n",
      "4           4      1    A           1  2010-06-04      17558.09       False   \n",
      "\n",
      "   temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0       5.727778              0.679451         8.106  \n",
      "1       8.055556              0.693452         8.106  \n",
      "2      16.816667              0.718284         7.808  \n",
      "3      22.527778              0.748928         7.808  \n",
      "4      27.050000              0.714586         7.808  \n"
     ]
    }
   ],
   "source": [
    "# Print the head of the sales DataFrame\n",
    "print(sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89c526a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10774 entries, 0 to 10773\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Unnamed: 0            10774 non-null  int64  \n",
      " 1   store                 10774 non-null  int64  \n",
      " 2   type                  10774 non-null  object \n",
      " 3   department            10774 non-null  int64  \n",
      " 4   date                  10774 non-null  object \n",
      " 5   weekly_sales          10774 non-null  float64\n",
      " 6   is_holiday            10774 non-null  bool   \n",
      " 7   temperature_c         10774 non-null  float64\n",
      " 8   fuel_price_usd_per_l  10774 non-null  float64\n",
      " 9   unemployment          10774 non-null  float64\n",
      "dtypes: bool(1), float64(4), int64(3), object(2)\n",
      "memory usage: 768.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print the info about the sales DataFrame\n",
    "print(sales.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23c995f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23843.950148505668\n"
     ]
    }
   ],
   "source": [
    "# Print the mean of weekly_sales\n",
    "print(sales['weekly_sales'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bf9aa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12049.064999999999\n"
     ]
    }
   ],
   "source": [
    "# Print the median of weekly_sales\n",
    "print(sales['weekly_sales'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a631b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-10-26\n",
      "2010-02-05\n"
     ]
    }
   ],
   "source": [
    "# Print the maximum of the date column\n",
    "print(sales[\"date\"].max())\n",
    "\n",
    "# Print the minimum of the date column\n",
    "print(sales[\"date\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa591151",
   "metadata": {},
   "source": [
    "Use the custom iqr function defined for you along with .agg() to print the IQR of the temperature_c column of sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cfc23f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.583333333333336\n"
     ]
    }
   ],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "# Print IQR of the temperature_c column\n",
    "print(sales['temperature_c'].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5a20b",
   "metadata": {},
   "source": [
    "Update the column selection to use the custom iqr function with .agg() to print the IQR of temperature_c, fuel_price_usd_per_l, and unemployment, in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36bc3bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature_c           16.583333\n",
      "fuel_price_usd_per_l     0.073176\n",
      "unemployment             0.565000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ba960",
   "metadata": {},
   "source": [
    "Update the aggregation functions called by .agg(): include iqr and np.median in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e0e70bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        temperature_c  fuel_price_usd_per_l  unemployment\n",
      "iqr         16.583333              0.073176         0.565\n",
      "median      16.966667              0.743381         8.099\n"
     ]
    }
   ],
   "source": [
    "# Import NumPy and create custom IQR function\n",
    "import numpy as np\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr, np.median]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7a7a18",
   "metadata": {},
   "source": [
    "### Dropping Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98213360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  store type  department        date  weekly_sales  \\\n",
      "0              0      1    A           1  2010-02-05      24924.50   \n",
      "901          901      2    A           1  2010-02-05      35034.06   \n",
      "1798        1798      4    A           1  2010-02-05      38724.42   \n",
      "2699        2699      6    A           1  2010-02-05      25619.00   \n",
      "3593        3593     10    B           1  2010-02-05      40212.84   \n",
      "\n",
      "      is_holiday  temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0          False       5.727778              0.679451         8.106  \n",
      "901        False       4.550000              0.679451         8.324  \n",
      "1798       False       6.533333              0.686319         8.623  \n",
      "2699       False       4.683333              0.679451         7.259  \n",
      "3593       False      12.411111              0.782478         9.765  \n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate store/type combinations\n",
    "store_types = sales.drop_duplicates(subset =['store','type'])\n",
    "print(store_types.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "475e2e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0  store type  department        date  weekly_sales  is_holiday  \\\n",
      "0            0      1    A           1  2010-02-05      24924.50       False   \n",
      "12          12      1    A           2  2010-02-05      50605.27       False   \n",
      "24          24      1    A           3  2010-02-05      13740.12       False   \n",
      "36          36      1    A           4  2010-02-05      39954.04       False   \n",
      "48          48      1    A           5  2010-02-05      32229.38       False   \n",
      "\n",
      "    temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0        5.727778              0.679451         8.106  \n",
      "12       5.727778              0.679451         8.106  \n",
      "24       5.727778              0.679451         8.106  \n",
      "36       5.727778              0.679451         8.106  \n",
      "48       5.727778              0.679451         8.106  \n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate store/department combinations\n",
    "store_depts = sales.drop_duplicates(subset=['store','department'])\n",
    "print(store_depts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa8f28a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498     2010-09-10\n",
      "691     2011-11-25\n",
      "2315    2010-02-12\n",
      "6735    2012-09-07\n",
      "6810    2010-12-31\n",
      "6815    2012-02-10\n",
      "6820    2011-09-09\n",
      "Name: date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Subset the rows where is_holiday is True and drop duplicate dates\n",
    "holiday_dates = sales[sales['is_holiday']].drop_duplicates(subset='date')\n",
    "\n",
    "# Print date col of holiday_dates\n",
    "print(holiday_dates['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a68d526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    11\n",
      "B     1\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of stores of each type\n",
    "store_counts = store_types['type'].value_counts()\n",
    "print(store_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54b4f628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    0.916667\n",
      "B    0.083333\n",
      "Name: type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get the proportion of stores of each type\n",
    "store_props = store_types['type'].value_counts(normalize=True)\n",
    "print(store_props)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef286944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     12\n",
      "55    12\n",
      "72    12\n",
      "71    12\n",
      "67    12\n",
      "      ..\n",
      "37    10\n",
      "48     8\n",
      "50     6\n",
      "39     4\n",
      "43     2\n",
      "Name: department, Length: 80, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of each department number and sort\n",
    "dept_counts_sorted = store_depts['department'].value_counts(sort=True)\n",
    "print(dept_counts_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8adc16fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     0.012917\n",
      "55    0.012917\n",
      "72    0.012917\n",
      "71    0.012917\n",
      "67    0.012917\n",
      "        ...   \n",
      "37    0.010764\n",
      "48    0.008611\n",
      "50    0.006459\n",
      "39    0.004306\n",
      "43    0.002153\n",
      "Name: department, Length: 80, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get the proportion of departments of each number and sort\n",
    "dept_props_sorted = store_depts['department'].value_counts(sort=True, normalize=True)\n",
    "print(dept_props_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7745352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9097747 0.0902253 0.       ]\n"
     ]
    }
   ],
   "source": [
    "# Calc total weekly sales\n",
    "sales_all = sales[\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type A stores, calc total weekly sales\n",
    "sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type B stores, calc total weekly sales\n",
    "sales_B = sales[sales[\"type\"] == \"B\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type C stores, calc total weekly sales\n",
    "sales_C = sales[sales[\"type\"] == \"C\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Get proportion for each type\n",
    "sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac87aa",
   "metadata": {},
   "source": [
    "## Calculations with .groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a39146c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "A    0.909775\n",
      "B    0.090225\n",
      "Name: weekly_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group by type; calc total weekly sales\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "# Get proportion for each type\n",
    "sales_propn_by_type = sales_by_type / sum(sales_by_type)\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9397db02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type  is_holiday\n",
      "A     False         2.336927e+08\n",
      "      True          2.360181e+04\n",
      "B     False         2.317678e+07\n",
      "      True          1.621410e+03\n",
      "Name: weekly_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group by type and is_holiday; calc total weekly sales\n",
    "sales_by_type_is_holiday = sales.groupby([\"type\",\"is_holiday\"])[\"weekly_sales\"].sum()\n",
    "print(sales_by_type_is_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f0ec7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        amin       amax          mean    median\n",
      "type                                           \n",
      "A    -1098.0  293966.05  23674.667242  11943.92\n",
      "B     -798.0  232558.51  25696.678370  13336.08\n"
     ]
    }
   ],
   "source": [
    "# For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
    "sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([np.min,np.max,np.mean,np.median])\n",
    "\n",
    "# Print sales_stats\n",
    "print(sales_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4577c4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     unemployment                         fuel_price_usd_per_l            \\\n",
      "             amin   amax      mean median                 amin      amax   \n",
      "type                                                                       \n",
      "A           3.879  8.992  7.972611  8.067             0.664129  1.107410   \n",
      "B           7.170  9.765  9.279323  9.199             0.760023  1.107674   \n",
      "\n",
      "                          \n",
      "          mean    median  \n",
      "type                      \n",
      "A     0.744619  0.735455  \n",
      "B     0.805858  0.803348  \n"
     ]
    }
   ],
   "source": [
    "# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n",
    "unemp_fuel_stats = sales.groupby(\"type\")[[\"unemployment\",\"fuel_price_usd_per_l\"]].agg([np.min,np.max,np.mean,np.median])\n",
    "\n",
    "# Print unemp_fuel_stats\n",
    "print(unemp_fuel_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5250f97",
   "metadata": {},
   "source": [
    "## Pivot Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb382d2",
   "metadata": {},
   "source": [
    "Here the value argument is the column that you need to summarize and index column is the column that you need to groupby,  \n",
    "By default pivot tables take the mean value for each group.  \n",
    "For a different summary statistic you can use the aggfunc argument.\n",
    "To group by two variables you can pass the second variable name into the columns argument.\n",
    "You can use the fill_value argument to fill the missing values with 0.  \n",
    "If we set the margins = True in the last column and row you get the mean of each row and column not including the missing values that were filled with zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fae5c8a",
   "metadata": {},
   "source": [
    "Eg:  \n",
    "dogs.pivot_table( values=\"weight_kg\" , index=\"color\" , columns=\"breed\" , fill_value=0 , margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9486f4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      weekly_sales\n",
      "type              \n",
      "A     23674.667242\n",
      "B     25696.678370\n"
     ]
    }
   ],
   "source": [
    "# Pivot for mean weekly_sales for each store type\n",
    "mean_sales_by_type = sales.pivot_table(values=\"weekly_sales\", index=\"type\")\n",
    "\n",
    "# Print mean_sales_by_type\n",
    "print(mean_sales_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04aa14d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              mean       median\n",
      "      weekly_sales weekly_sales\n",
      "type                           \n",
      "A     23674.667242     11943.92\n",
      "B     25696.678370     13336.08\n"
     ]
    }
   ],
   "source": [
    "# Pivot for mean and median weekly_sales for each store type\n",
    "mean_med_sales_by_type = sales.pivot_table(values=\"weekly_sales\", index=\"type\", aggfunc=[np.mean, np.median])\n",
    "\n",
    "# Print mean_med_sales_by_type\n",
    "print(mean_med_sales_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be53b845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_holiday         False       True\n",
      "type                               \n",
      "A           23768.583523  590.04525\n",
      "B           25751.980533  810.70500\n"
     ]
    }
   ],
   "source": [
    "# Pivot for mean weekly_sales by store type and holiday \n",
    "mean_sales_by_type_holiday = sales.pivot_table(values=\"weekly_sales\", index=\"type\", columns=\"is_holiday\")\n",
    "\n",
    "# Print mean_sales_by_type_holiday\n",
    "print(mean_sales_by_type_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdda4b00",
   "metadata": {},
   "source": [
    "## Fill in missing values and sum values with pivot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f2b45fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type                    A              B\n",
      "department                              \n",
      "1            30961.725379   44050.626667\n",
      "2            67600.158788  112958.526667\n",
      "3            17160.002955   30580.655000\n",
      "4            44285.399091   51219.654167\n",
      "5            34821.011364   63236.875000\n",
      "...                   ...            ...\n",
      "95          123933.787121   77082.102500\n",
      "96           21367.042857    9528.538333\n",
      "97           28471.266970    5828.873333\n",
      "98           12875.423182     217.428333\n",
      "99             379.123659       0.000000\n",
      "\n",
      "[80 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print mean weekly_sales by department and type; fill missing values with 0\n",
    "print(sales.pivot_table(values=\"weekly_sales\",index=\"department\", columns=\"type\", fill_value = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89d37854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type                   A              B           All\n",
      "department                                           \n",
      "1           30961.725379   44050.626667  32052.467153\n",
      "2           67600.158788  112958.526667  71380.022778\n",
      "3           17160.002955   30580.655000  18278.390625\n",
      "4           44285.399091   51219.654167  44863.253681\n",
      "5           34821.011364   63236.875000  37189.000000\n",
      "...                  ...            ...           ...\n",
      "96          21367.042857    9528.538333  20337.607681\n",
      "97          28471.266970    5828.873333  26584.400833\n",
      "98          12875.423182     217.428333  11820.590278\n",
      "99            379.123659       0.000000    379.123659\n",
      "All         23674.667242   25696.678370  23843.950149\n",
      "\n",
      "[81 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the mean weekly_sales by department and type; fill missing values with 0s; sum all rows and cols\n",
    "print(sales.pivot_table(values=\"weekly_sales\", index=\"department\", columns=\"type\", fill_value=0, margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ce0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
