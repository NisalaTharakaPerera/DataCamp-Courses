{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "997e41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5276dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df = pd.read_csv(\"music_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c88ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36506</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.726</td>\n",
       "      <td>214547.0</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>-14.824</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>92.934</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37591</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.635</td>\n",
       "      <td>190448.0</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>-4.795</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>110.012</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37658</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.352</td>\n",
       "      <td>456320.0</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>-3.634</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>122.897</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36060</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>352280.0</td>\n",
       "      <td>0.3260</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>-12.020</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>106.063</td>\n",
       "      <td>0.3230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35710</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>273693.0</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>-7.787</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>143.995</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>44501</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.193</td>\n",
       "      <td>208040.0</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.929000</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>-28.228</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>82.165</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>25114</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.939</td>\n",
       "      <td>144453.0</td>\n",
       "      <td>0.3730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>-7.779</td>\n",
       "      <td>0.2270</td>\n",
       "      <td>119.953</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>46896</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.739</td>\n",
       "      <td>238339.0</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>-9.735</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>85.082</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>45135</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>0.515</td>\n",
       "      <td>286707.0</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>-5.606</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>150.063</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>18960</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.291</td>\n",
       "      <td>194679.0</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>-6.972</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>146.245</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0         36506        60.0      0.896000         0.726     214547.0  0.1770   \n",
       "1         37591        63.0      0.003840         0.635     190448.0  0.9080   \n",
       "2         37658        59.0      0.000075         0.352     456320.0  0.9560   \n",
       "3         36060        54.0      0.945000         0.488     352280.0  0.3260   \n",
       "4         35710        55.0      0.245000         0.667     273693.0  0.6470   \n",
       "..          ...         ...           ...           ...          ...     ...   \n",
       "995       44501        57.0      0.972000         0.193     208040.0  0.0329   \n",
       "996       25114        56.0      0.005790         0.939     144453.0  0.3730   \n",
       "997       46896        54.0      0.016100         0.739     238339.0  0.5390   \n",
       "998       45135        62.0      0.326000         0.515     286707.0  0.5050   \n",
       "999       18960        42.0      0.029500         0.291     194679.0  0.5980   \n",
       "\n",
       "     instrumentalness  liveness  loudness  speechiness    tempo  valence  \\\n",
       "0            0.000002    0.1160   -14.824       0.0353   92.934   0.6180   \n",
       "1            0.083400    0.2390    -4.795       0.0563  110.012   0.6370   \n",
       "2            0.020300    0.1250    -3.634       0.1490  122.897   0.2280   \n",
       "3            0.015700    0.1190   -12.020       0.0328  106.063   0.3230   \n",
       "4            0.000297    0.0633    -7.787       0.0487  143.995   0.3000   \n",
       "..                ...       ...       ...          ...      ...      ...   \n",
       "995          0.929000    0.0978   -28.228       0.0460   82.165   0.0366   \n",
       "996          0.000000    0.2740    -7.779       0.2270  119.953   0.0602   \n",
       "997          0.000000    0.2350    -9.735       0.3370   85.082   0.8350   \n",
       "998          0.000000    0.1020    -5.606       0.0294  150.063   0.5380   \n",
       "999          0.002270    0.0738    -6.972       0.0394  146.245   0.1860   \n",
       "\n",
       "     genre  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "..     ...  \n",
       "995      0  \n",
       "996      0  \n",
       "997      0  \n",
       "998      0  \n",
       "999      0  \n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b2fbb",
   "metadata": {},
   "source": [
    "## Creating dummy variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec4f6cf",
   "metadata": {},
   "source": [
    "Being able to include categorical features in the model building process can enhance performance as they may add information that contributes to prediction accuracy.   \n",
    "Now you will create a new DataFrame containing the original columns of music_df plus dummy variables from the \"genre\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4dcd1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of music_dummies: (1000, 13)\n"
     ]
    }
   ],
   "source": [
    "# Create music_dummies\n",
    "music_dummies = pd.get_dummies(music_df, drop_first=True)\n",
    "\n",
    "# Print the new DataFrame's shape\n",
    "print(\"Shape of music_dummies: {}\".format(music_dummies.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec3d63",
   "metadata": {},
   "source": [
    "## Regression with categorical features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803808f6",
   "metadata": {},
   "source": [
    "Now you have created music_dummies, containing binary features for each song's genre, it's time to build a ridge regression model to predict song popularity.\n",
    "\n",
    "The model will be evaluated by calculating the average RMSE, but first, you will need to convert the scores for each fold to positive values and take their square root. This metric shows the average error of our model's predictions, so it can be compared against the standard deviation of the target valueâ€”\"popularity\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08422012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1182af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3901df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 9.998909565816527\n",
      "Standard Deviation of the target array: 14.02156909907019\n"
     ]
    }
   ],
   "source": [
    "# Create X and y\n",
    "X = music_dummies.drop(\"popularity\", axis=1).values\n",
    "y = music_dummies[\"popularity\"].values\n",
    "\n",
    "#Â Instantiate a ridge model\n",
    "ridge = Ridge(alpha=0.2)\n",
    "\n",
    "#Â Perform cross-validation\n",
    "scores = cross_val_score(ridge, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "#Â Calculate RMSE\n",
    "rmse = np.sqrt(-scores)\n",
    "print(\"Average RMSE: {}\".format(np.mean(rmse)))\n",
    "print(\"Standard Deviation of the target array: {}\".format(np.std(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853daa5b",
   "metadata": {},
   "source": [
    "Great work! An average RMSE of approximately 8.24 is lower than the standard deviation of the target variable (song popularity), suggesting the model is reasonably accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100793f0",
   "metadata": {},
   "source": [
    "## Dropping missing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b99c936",
   "metadata": {},
   "source": [
    "Over the next three exercises, you are going to tidy the music_df dataset. You will create a pipeline to impute missing values and build a KNN classifier model, then use it to predict whether a song is of the \"Rock\" genre.\n",
    "\n",
    "In this exercise specifically, you will drop missing values accounting for less than 5% of the dataset, and convert the \"genre\" column into a binary feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13e2395",
   "metadata": {},
   "source": [
    "Print the number of missing values for each column in the music_df dataset, sorted in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "819618d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          0\n",
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print missing values for each column\n",
    "print(music_df.isna().sum().sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd73aa0a",
   "metadata": {},
   "source": [
    "In the above dataset you don't have any null value, but in the exercise eventhough the dataset has the same name it has null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16265252",
   "metadata": {},
   "source": [
    "Remove values for all columns with 50 or fewer missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74dd45ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove values where less than 5% are missing\n",
    "music_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f9759e",
   "metadata": {},
   "source": [
    "Convert music_df[\"genre\"] to values of 1 if the row contains \"Rock\", otherwise change the value to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0106d500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          0\n",
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n",
      "Shape of the `music_df`: (1000, 13)\n"
     ]
    }
   ],
   "source": [
    "# Convert genre to a binary feature\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "\n",
    "print(music_df.isna().sum().sort_values())\n",
    "print(\"Shape of the `music_df`: {}\".format(music_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc77bac",
   "metadata": {},
   "source": [
    "The dataset in the exercise has gone from 1000 observations down to 892, but it is now in the correct format for binary classification and the remaining missing values can be imputed as part of a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3fa244",
   "metadata": {},
   "source": [
    "## Pipeline for song genre prediction: I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5b0a6",
   "metadata": {},
   "source": [
    "Now it's time to build a pipeline. It will contain steps to impute missing values using the mean for each feature and build a KNN model for the classification of song genre.\n",
    "\n",
    "The modified music_df dataset that you created in the previous exercise has been preloaded for you, along with KNeighborsClassifier and train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17b72f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2c93f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an imputer\n",
    "imputer = SimpleImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae638ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Instantiate a knn model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a12aab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build steps for the pipeline\n",
    "steps = [(\"imputer\", imputer), \n",
    "         (\"knn\", knn)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ed68f2",
   "metadata": {},
   "source": [
    "## Pipeline for song genre prediction: II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef105e54",
   "metadata": {},
   "source": [
    "Having set up the steps of the pipeline in the previous exercise, you will now use it on the music_df dataset to classify the genre of songs. What makes pipelines so incredibly useful is the simple interface that they provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b22cf142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfde9e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36506</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.726</td>\n",
       "      <td>214547.0</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>-14.824</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>92.934</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37591</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.635</td>\n",
       "      <td>190448.0</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>-4.795</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>110.012</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37658</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.352</td>\n",
       "      <td>456320.0</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>-3.634</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>122.897</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36060</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>352280.0</td>\n",
       "      <td>0.3260</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>-12.020</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>106.063</td>\n",
       "      <td>0.3230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35710</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>273693.0</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>-7.787</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>143.995</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>44501</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.193</td>\n",
       "      <td>208040.0</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.929000</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>-28.228</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>82.165</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>25114</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.939</td>\n",
       "      <td>144453.0</td>\n",
       "      <td>0.3730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>-7.779</td>\n",
       "      <td>0.2270</td>\n",
       "      <td>119.953</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>46896</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.739</td>\n",
       "      <td>238339.0</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>-9.735</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>85.082</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>45135</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>0.515</td>\n",
       "      <td>286707.0</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>-5.606</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>150.063</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>18960</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.291</td>\n",
       "      <td>194679.0</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>-6.972</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>146.245</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0         36506        60.0      0.896000         0.726     214547.0  0.1770   \n",
       "1         37591        63.0      0.003840         0.635     190448.0  0.9080   \n",
       "2         37658        59.0      0.000075         0.352     456320.0  0.9560   \n",
       "3         36060        54.0      0.945000         0.488     352280.0  0.3260   \n",
       "4         35710        55.0      0.245000         0.667     273693.0  0.6470   \n",
       "..          ...         ...           ...           ...          ...     ...   \n",
       "995       44501        57.0      0.972000         0.193     208040.0  0.0329   \n",
       "996       25114        56.0      0.005790         0.939     144453.0  0.3730   \n",
       "997       46896        54.0      0.016100         0.739     238339.0  0.5390   \n",
       "998       45135        62.0      0.326000         0.515     286707.0  0.5050   \n",
       "999       18960        42.0      0.029500         0.291     194679.0  0.5980   \n",
       "\n",
       "     instrumentalness  liveness  loudness  speechiness    tempo  valence  \\\n",
       "0            0.000002    0.1160   -14.824       0.0353   92.934   0.6180   \n",
       "1            0.083400    0.2390    -4.795       0.0563  110.012   0.6370   \n",
       "2            0.020300    0.1250    -3.634       0.1490  122.897   0.2280   \n",
       "3            0.015700    0.1190   -12.020       0.0328  106.063   0.3230   \n",
       "4            0.000297    0.0633    -7.787       0.0487  143.995   0.3000   \n",
       "..                ...       ...       ...          ...      ...      ...   \n",
       "995          0.929000    0.0978   -28.228       0.0460   82.165   0.0366   \n",
       "996          0.000000    0.2740    -7.779       0.2270  119.953   0.0602   \n",
       "997          0.000000    0.2350    -9.735       0.3370   85.082   0.8350   \n",
       "998          0.000000    0.1020    -5.606       0.0294  150.063   0.5380   \n",
       "999          0.002270    0.0738    -6.972       0.0394  146.245   0.1860   \n",
       "\n",
       "     genre  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "995      0  \n",
       "996      0  \n",
       "997      0  \n",
       "998      0  \n",
       "999      0  \n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b475aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To drop the column in the 0th index\n",
    "music_df = music_df.drop(music_df.columns[[0]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9e881f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.726</td>\n",
       "      <td>214547.0</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>-14.824</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>92.934</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.635</td>\n",
       "      <td>190448.0</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>-4.795</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>110.012</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.352</td>\n",
       "      <td>456320.0</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>-3.634</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>122.897</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>352280.0</td>\n",
       "      <td>0.3260</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>-12.020</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>106.063</td>\n",
       "      <td>0.3230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>273693.0</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>-7.787</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>143.995</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.193</td>\n",
       "      <td>208040.0</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.929000</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>-28.228</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>82.165</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.939</td>\n",
       "      <td>144453.0</td>\n",
       "      <td>0.3730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>-7.779</td>\n",
       "      <td>0.2270</td>\n",
       "      <td>119.953</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.739</td>\n",
       "      <td>238339.0</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>-9.735</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>85.082</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>0.515</td>\n",
       "      <td>286707.0</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>-5.606</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>150.063</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.291</td>\n",
       "      <td>194679.0</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>-6.972</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>146.245</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0          60.0      0.896000         0.726     214547.0  0.1770   \n",
       "1          63.0      0.003840         0.635     190448.0  0.9080   \n",
       "2          59.0      0.000075         0.352     456320.0  0.9560   \n",
       "3          54.0      0.945000         0.488     352280.0  0.3260   \n",
       "4          55.0      0.245000         0.667     273693.0  0.6470   \n",
       "..          ...           ...           ...          ...     ...   \n",
       "995        57.0      0.972000         0.193     208040.0  0.0329   \n",
       "996        56.0      0.005790         0.939     144453.0  0.3730   \n",
       "997        54.0      0.016100         0.739     238339.0  0.5390   \n",
       "998        62.0      0.326000         0.515     286707.0  0.5050   \n",
       "999        42.0      0.029500         0.291     194679.0  0.5980   \n",
       "\n",
       "     instrumentalness  liveness  loudness  speechiness    tempo  valence  \\\n",
       "0            0.000002    0.1160   -14.824       0.0353   92.934   0.6180   \n",
       "1            0.083400    0.2390    -4.795       0.0563  110.012   0.6370   \n",
       "2            0.020300    0.1250    -3.634       0.1490  122.897   0.2280   \n",
       "3            0.015700    0.1190   -12.020       0.0328  106.063   0.3230   \n",
       "4            0.000297    0.0633    -7.787       0.0487  143.995   0.3000   \n",
       "..                ...       ...       ...          ...      ...      ...   \n",
       "995          0.929000    0.0978   -28.228       0.0460   82.165   0.0366   \n",
       "996          0.000000    0.2740    -7.779       0.2270  119.953   0.0602   \n",
       "997          0.000000    0.2350    -9.735       0.3370   85.082   0.8350   \n",
       "998          0.000000    0.1020    -5.606       0.0294  150.063   0.5380   \n",
       "999          0.002270    0.0738    -6.972       0.0394  146.245   0.1860   \n",
       "\n",
       "     genre  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "995      0  \n",
       "996      0  \n",
       "997      0  \n",
       "998      0  \n",
       "999      0  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23402b60",
   "metadata": {},
   "source": [
    "## Pipeline for song genre prediction: II\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf42aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = music_df.drop(\"genre\", axis=1).values\n",
    "y = music_df[\"genre\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89c255cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6717e285",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imp_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13212\\2105036177.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m steps = [(\"imputer\", imp_mean),\n\u001b[0m\u001b[0;32m      2\u001b[0m         (\"knn\", knn)]\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create the pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imp_mean' is not defined"
     ]
    }
   ],
   "source": [
    "steps = [(\"imputer\", imp_mean),\n",
    "        (\"knn\", knn)]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fe742",
   "metadata": {},
   "source": [
    "## Centering and scaling for regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535fae05",
   "metadata": {},
   "source": [
    "Now you have seen the benefits of scaling your data, you will use a pipeline to preprocess the music_df features and build a lasso regression model to predict a song's loudness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97560cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31b88015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ede9e",
   "metadata": {},
   "source": [
    "Create the steps for the pipeline object, a StandardScaler object called \"scaler\", and a lasso model called \"lasso\" with alpha set to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9fadd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"lasso\", Lasso(alpha=0.5))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1987f510",
   "metadata": {},
   "source": [
    "Instantiate a pipeline with steps to scale and build a lasso regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "faeaf251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('lasso', Lasso(alpha=0.5))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b541697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Â Calculate and print R-squared\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b161b6",
   "metadata": {},
   "source": [
    "The answer I got in the exercise is 0.61935"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a62c4e7",
   "metadata": {},
   "source": [
    "The model may have only produced an R-squared of 0.619, but without scaling this exact model would have only produced a score of 0.35, which proves just how powerful scaling can be!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36827379",
   "metadata": {},
   "source": [
    "## Centering and scaling for classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb6b888",
   "metadata": {},
   "source": [
    "Now you will bring together scaling and model building into a pipeline for cross-validation.\n",
    "\n",
    "Your task is to build a pipeline to scale features in the music_df dataset and perform grid search cross-validation using a logistic regression model with different values for the hyperparameter C. The target variable here is \"genre\", which contains binary values for rock as 1 and any other genre as 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7634e",
   "metadata": {},
   "source": [
    "Build the steps for the pipeline: a StandardScaler() object named \"scaler\", and a logistic regression model named \"logreg\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7f68308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcef0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"logreg\", LogisticRegression())]\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aed60d6",
   "metadata": {},
   "source": [
    "Create the parameters, searching 20 equally spaced float values ranging from 0.001 to 1.0 for the logistic regression model's C hyperparameter within the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f72b0c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter space\n",
    "parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13324f6e",
   "metadata": {},
   "source": [
    "Instantiate the grid search object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdd60024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cc42ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search object\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10469912",
   "metadata": {},
   "source": [
    "Fit the grid search object to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "577cf80f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "100 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1554, in fit\n",
      "    raise ValueError(\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13212\\2452310993.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit to the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1552\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1554\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1555\u001b[0m                 \u001b[1;34m\"This solver needs samples of at least 2 classes\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1556\u001b[0m                 \u001b[1;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "# Fit to the training data\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3137471",
   "metadata": {},
   "source": [
    "Using a pipeline shows that a logistic regression model with \"C\" set to approximately 0.1 produces a model with 0.8425 accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b41936",
   "metadata": {},
   "source": [
    "## Visualizing regression model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da788ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd24e6cd",
   "metadata": {},
   "source": [
    "Now you have seen how to evaluate multiple models out of the box, you will build three regression models to predict a song's \"energy\" levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3c23f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"Linear Regression\": LinearRegression(), \"Ridge\": Ridge(alpha=0.1), \"Lasso\": Lasso(alpha=0.1)}\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f0270",
   "metadata": {},
   "source": [
    "Write a for loop using model as the iterator, and model.values() as the iterable.   \n",
    "Perform cross-validation on the training features and the training target array using the model, setting cv equal to the KFold object.   \n",
    "Append the model's cross-validation scores to the results list.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58435e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "  \n",
    "  # Append the results\n",
    "  results.append(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e72f1e",
   "metadata": {},
   "source": [
    "Create a box plot displaying the results, with the x-axis labels as the names of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b49de297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a box plot of the results\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22257f",
   "metadata": {},
   "source": [
    "Lasso regression is not a good model for this problem, while linear regression and ridge perform fairly equally. Let's make predictions on the test set, and see if the RMSE can guide us on model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e5de8d",
   "metadata": {},
   "source": [
    "## Predicting on the test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986b90bb",
   "metadata": {},
   "source": [
    "In the last exercise, linear regression and ridge appeared to produce similar results. It would be appropriate to select either of those models; however, you can check predictive performance on the test set to see if either one can outperform the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "beac6602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a2cdb1",
   "metadata": {},
   "source": [
    "Import mean_squared_error.   \n",
    "Fit the model to the scaled training features and the training labels.   \n",
    "Make predictions using the scaled test features.   \n",
    "Calculate RMSE by passing the test set labels and the predicted labels.  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5cbcd7",
   "metadata": {},
   "source": [
    "###### Import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for name, model in models.items():\n",
    "  \n",
    "  ######  Fit the model to the training data\n",
    "  model.fit(X_train_scaled, y_train)\n",
    "  \n",
    "  ######  Make predictions on the test set\n",
    "  y_pred = model.predict(X_test_scaled)\n",
    "  \n",
    "  ######  Calculate the test_rmse\n",
    "  test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "  print(\"{} Test Set RMSE: {}\".format(name, test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cef94c",
   "metadata": {},
   "source": [
    "<script.py> output:   \n",
    "    Linear Regression Test Set RMSE: 0.1198885150594757   \n",
    "    Ridge Test Set RMSE: 0.11987066103299669   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8332c",
   "metadata": {},
   "source": [
    "The linear regression model just edges the best performance, although the difference is a RMSE of 0.00001 for popularity! Now let's look at classification model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a082ee4",
   "metadata": {},
   "source": [
    "## Visualizing classification model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bbabfa",
   "metadata": {},
   "source": [
    "In this exercise, you will be solving a classification problem where the \"popularity\" column in the music_df dataset has been converted to binary values, with 1 representing popularity more than or equal to the median for the \"popularity\" column, and 0 indicating popularity below the median.\n",
    "\n",
    "Your task is to build and visualize the results of three different models to classify whether a song is popular or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380545f2",
   "metadata": {},
   "source": [
    "* Create a dictionary of \"Logistic Regression\", \"KNN\", and \"Decision Tree Classifier\", setting the dictionary's values to a call of each model.   \n",
    "* Loop through the values in models.   \n",
    "* Instantiate a KFold object to perform 6 splits, setting shuffle to True and random_state to 12.   \n",
    "* Perform cross-validation using the model, the scaled training features, the target training set, and setting cv equal to kf.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7eae80",
   "metadata": {},
   "source": [
    "###### Create models dictionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(), \"KNN\": KNeighborsClassifier(), \"Decision Tree Classifier\": DecisionTreeClassifier()}\n",
    "results = []\n",
    "\n",
    "###### Loop through the models' values\n",
    "for model in models.values():\n",
    "  \n",
    "  ###### Instantiate a KFold object\n",
    "  kf = KFold(n_splits=6, random_state=12, shuffle=True)\n",
    "  \n",
    "  ###### Perform cross-validation\n",
    "  cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "  results.append(cv_results)\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c05ac79",
   "metadata": {},
   "source": [
    "## Pipeline for predicting song popularity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc0d8f",
   "metadata": {},
   "source": [
    "For the final exercise, you will build a pipeline to impute missing values, scale features, and perform hyperparameter tuning of a logistic regression model. The aim is to find the best parameters and accuracy when predicting song genre!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f906ce",
   "metadata": {},
   "source": [
    "* Create the steps for the pipeline by calling a simple imputer, a standard scaler, and a logistic regression model.   \n",
    "* Create a pipeline object, and pass the steps variable.   \n",
    "* Instantiate a grid search object to perform cross-validation using the pipeline and the parameters.   \n",
    "* Print the best parameters and compute and print the test set accuracy score for the grid search object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdae130",
   "metadata": {},
   "source": [
    "###### Create steps\n",
    "steps = [(\"imp_mean\", SimpleImputer()), \n",
    "         (\"scaler\", StandardScaler()), \n",
    "         (\"logreg\", LogisticRegression())]\n",
    "\n",
    "###### Set up pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "params = {\"logreg__solver\": [\"newton-cg\", \"saga\", \"lbfgs\"],\n",
    "         \"logreg__C\": np.linspace(0.001, 1.0, 10)}\n",
    "\n",
    "###### Create the GridSearchCV object\n",
    "tuning = GridSearchCV(pipeline, param_grid=params)\n",
    "tuning.fit(X_train, y_train)\n",
    "y_pred = tuning.predict(X_test)\n",
    "\n",
    "###### Compute and print performance\n",
    "print(\"Tuned Logistic Regression Parameters: {}, Accuracy: {}\".format(tuning.best_params_, tuning.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e4dea7",
   "metadata": {},
   "source": [
    "Excellent - you've selected a model, built a preprocessing pipeline, and performed hyperparameter tuning to create a model that is 82% accurate in predicting song genres!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46df975d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
